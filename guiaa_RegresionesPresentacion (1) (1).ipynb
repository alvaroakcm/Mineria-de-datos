{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89a0cb8-aa8f-4db3-b752-45a41a8ed2fd",
   "metadata": {},
   "source": [
    "# üß† An√°lisis Predictivo del Bienestar y Estilo de Vida ‚Äî *Work-Life Balance Model*\n",
    "\n",
    "## üìò Introducci√≥n\n",
    "\n",
    "Este notebook presenta un proyecto completo de **modelado predictivo** basado en el dataset **\"Wellbeing and Lifestyle Data\" (Kaggle)**.  \n",
    "El objetivo principal es **predecir el puntaje de equilibrio vida-trabajo (`WORK_LIFE_BALANCE_SCORE`)** a partir de variables relacionadas con h√°bitos, salud, logros personales y condiciones sociales.\n",
    "\n",
    "### üîç Enfoque general del proyecto:\n",
    "1. **Preparaci√≥n de datos:** limpieza, codificaci√≥n y separaci√≥n de variables predictoras (`X`) y objetivo (`y`).  \n",
    "2. **Entrenamiento inicial (Baseline):** comparaci√≥n de distintos modelos de regresi√≥n (Lineal, Ridge, RandomForest, MLP, etc.).  \n",
    "3. **Optimizaci√≥n (Tuning):** ajuste de hiperpar√°metros para mejorar la precisi√≥n del modelo.  \n",
    "4. **Selecci√≥n y evaluaci√≥n final:** comparaci√≥n justa entre el modelo base y el optimizado, eligiendo el de mejor rendimiento.  \n",
    "5. **An√°lisis interpretativo:** evaluaci√≥n de la importancia de las variables, errores individuales y comportamiento por subgrupos.\n",
    "\n",
    "### ‚öôÔ∏è Tecnolog√≠as utilizadas:\n",
    "- **Python / scikit-learn / imbalanced-learn** para la construcci√≥n y validaci√≥n del modelo.  \n",
    "- **XGBoost, LightGBM y CatBoost** para pruebas avanzadas de regresi√≥n.  \n",
    "- **Matplotlib y Pandas** para an√°lisis exploratorio y visualizaci√≥n.  \n",
    "\n",
    "### üéØ Resultado esperado:\n",
    "El notebook busca construir un modelo **preciso, interpretable y estable**, capaz de identificar los factores que m√°s influyen en el bienestar personal y laboral.  \n",
    "Adem√°s, se incluye un an√°lisis de **error y equidad por subgrupos**, garantizando que el modelo sea confiable y √©tico en su aplicaci√≥n.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6027230-6449-4b70-b158-7c4c24895a53",
   "metadata": {},
   "source": [
    "# üß≠ Paso 1: Cargar los datos y definir la variable objetivo\n",
    "\n",
    "En este primer bloque, se prepara el entorno de trabajo y se cargan los datos desde el archivo CSV **‚ÄúWellbeing_and_lifestyle_data_Kaggle.csv‚Äù**.  \n",
    "El objetivo es tener el conjunto de datos listo para los siguientes pasos del an√°lisis predictivo.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Objetivo del paso\n",
    "1. Importar las librer√≠as necesarias (`numpy`, `pandas`, `os`, etc.).\n",
    "2. Establecer una semilla aleatoria (`RANDOM_STATE = 42`) para garantizar reproducibilidad.\n",
    "3. Cargar el archivo CSV y revisar su estructura inicial.\n",
    "4. Convertir variables categ√≥ricas (`DAILY_STRESS`, `AGE`, `GENDER`) a formato num√©rico.\n",
    "5. Separar la variable **objetivo** (`WORK_LIFE_BALANCE_SCORE`) de las variables **predictoras** (`X`).\n",
    "\n",
    "---\n",
    "\n",
    "### üìò Explicaci√≥n del c√≥digo\n",
    "\n",
    "- `warnings.filterwarnings(\"ignore\")` ‚Üí suprime avisos para mantener la salida limpia.  \n",
    "- `assert os.path.exists(DATA_FILE)` ‚Üí verifica que el archivo exista antes de cargarlo.  \n",
    "- `df.info()` ‚Üí muestra un resumen con el n√∫mero de filas, tipos de datos y columnas.\n",
    "\n",
    "Despu√©s de convertir las variables categ√≥ricas:\n",
    "- `DAILY_STRESS` y `AGE` pasan de tipo *object* a *int8* (valores num√©ricos codificados).  \n",
    "- `GENDER` se mapea a 0 = *Female*, 1 = *Male*.  \n",
    "- El resto de variables ya son num√©ricas, por lo que no requieren transformaci√≥n.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3634a416-4dee-4529-87b4-c3befe44a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15972 entries, 0 to 15971\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Timestamp                15972 non-null  object \n",
      " 1   FRUITS_VEGGIES           15972 non-null  int64  \n",
      " 2   DAILY_STRESS             15972 non-null  object \n",
      " 3   PLACES_VISITED           15972 non-null  int64  \n",
      " 4   CORE_CIRCLE              15972 non-null  int64  \n",
      " 5   SUPPORTING_OTHERS        15972 non-null  int64  \n",
      " 6   SOCIAL_NETWORK           15972 non-null  int64  \n",
      " 7   ACHIEVEMENT              15972 non-null  int64  \n",
      " 8   DONATION                 15972 non-null  int64  \n",
      " 9   BMI_RANGE                15972 non-null  int64  \n",
      " 10  TODO_COMPLETED           15972 non-null  int64  \n",
      " 11  FLOW                     15972 non-null  int64  \n",
      " 12  DAILY_STEPS              15972 non-null  int64  \n",
      " 13  LIVE_VISION              15972 non-null  int64  \n",
      " 14  SLEEP_HOURS              15972 non-null  int64  \n",
      " 15  LOST_VACATION            15972 non-null  int64  \n",
      " 16  DAILY_SHOUTING           15972 non-null  int64  \n",
      " 17  SUFFICIENT_INCOME        15972 non-null  int64  \n",
      " 18  PERSONAL_AWARDS          15972 non-null  int64  \n",
      " 19  TIME_FOR_PASSION         15972 non-null  int64  \n",
      " 20  WEEKLY_MEDITATION        15972 non-null  int64  \n",
      " 21  AGE                      15972 non-null  object \n",
      " 22  GENDER                   15972 non-null  object \n",
      " 23  WORK_LIFE_BALANCE_SCORE  15972 non-null  float64\n",
      "dtypes: float64(1), int64(19), object(4)\n",
      "memory usage: 2.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15972 entries, 0 to 15971\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Timestamp                15972 non-null  object \n",
      " 1   FRUITS_VEGGIES           15972 non-null  int64  \n",
      " 2   DAILY_STRESS             15972 non-null  int8   \n",
      " 3   PLACES_VISITED           15972 non-null  int64  \n",
      " 4   CORE_CIRCLE              15972 non-null  int64  \n",
      " 5   SUPPORTING_OTHERS        15972 non-null  int64  \n",
      " 6   SOCIAL_NETWORK           15972 non-null  int64  \n",
      " 7   ACHIEVEMENT              15972 non-null  int64  \n",
      " 8   DONATION                 15972 non-null  int64  \n",
      " 9   BMI_RANGE                15972 non-null  int64  \n",
      " 10  TODO_COMPLETED           15972 non-null  int64  \n",
      " 11  FLOW                     15972 non-null  int64  \n",
      " 12  DAILY_STEPS              15972 non-null  int64  \n",
      " 13  LIVE_VISION              15972 non-null  int64  \n",
      " 14  SLEEP_HOURS              15972 non-null  int64  \n",
      " 15  LOST_VACATION            15972 non-null  int64  \n",
      " 16  DAILY_SHOUTING           15972 non-null  int64  \n",
      " 17  SUFFICIENT_INCOME        15972 non-null  int64  \n",
      " 18  PERSONAL_AWARDS          15972 non-null  int64  \n",
      " 19  TIME_FOR_PASSION         15972 non-null  int64  \n",
      " 20  WEEKLY_MEDITATION        15972 non-null  int64  \n",
      " 21  AGE                      15972 non-null  int8   \n",
      " 22  GENDER                   15972 non-null  int64  \n",
      " 23  WORK_LIFE_BALANCE_SCORE  15972 non-null  float64\n",
      "dtypes: float64(1), int64(20), int8(2), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "Shape: (15972, 22) | y(mean): 666.7515 | y(std): 45.0199 | y[min,max]: (480.0, 820.2)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1) Cargar datos y objetivo\n",
    "# =========================================\n",
    "import os, json, warnings, platform, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Archivo y variable objetivo\n",
    "DATA_FILE = \"Wellbeing_and_lifestyle_data_Kaggle.csv\"     # <-- tu archivo limpio\n",
    "TARGET    = \"WORK_LIFE_BALANCE_SCORE\"                     # variable objetivo num√©rica\n",
    "assert os.path.exists(DATA_FILE), f\"No se encuentra {DATA_FILE}\"\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df.info()\n",
    "\n",
    "# =========================================\n",
    "# Adaptaci√≥n a tus columnas reales\n",
    "# =========================================\n",
    "# El dataset no tiene 'clase_salario', por eso lo eliminamos\n",
    "# En su lugar, codificamos las variables categ√≥ricas relevantes\n",
    "\n",
    "# Convertir variables categ√≥ricas a num√©ricas\n",
    "df[\"DAILY_STRESS\"] = df[\"DAILY_STRESS\"].astype(\"category\").cat.codes\n",
    "df[\"AGE\"] = df[\"AGE\"].astype(\"category\").cat.codes\n",
    "df[\"GENDER\"] = df[\"GENDER\"].map({\"Female\": 0, \"Male\": 1})\n",
    "\n",
    "# Verificar resultado\n",
    "df.info()\n",
    "\n",
    "# =========================================\n",
    "# Definir variable objetivo y predictoras\n",
    "# =========================================\n",
    "y  = df[TARGET]\n",
    "X  = df.drop(columns=[TARGET, \"Timestamp\"])\n",
    "\n",
    "print(\"Shape:\", X.shape,\n",
    "      \"| y(mean):\", round(y.mean(), 4),\n",
    "      \"| y(std):\", round(y.std(), 4),\n",
    "      \"| y[min,max]:\", (round(y.min(), 4), round(y.max(), 4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c76ecb-665a-4b08-b521-84b310a3cc49",
   "metadata": {},
   "source": [
    "### üìä Resultados principales\n",
    "\n",
    "- **Registros:** 15,972  \n",
    "- **Columnas totales:** 24  \n",
    "- **Variables predictoras (X):** 22 columnas (tras eliminar `Timestamp` y la variable objetivo).  \n",
    "- **Variable objetivo (y):** `WORK_LIFE_BALANCE_SCORE` (num√©rica continua).\n",
    "\n",
    "El resumen final del dataset fue:\n",
    "\n",
    "Shape: (15972, 22) | y(mean): 666.7515 | y(std): 45.0199 | y[min,max]: (480.0, 820.2)\n",
    "\n",
    "\n",
    "Esto significa:\n",
    "- El conjunto tiene **15,972 observaciones** y **22 variables predictoras**.  \n",
    "- El puntaje promedio de bienestar laboral (`WORK_LIFE_BALANCE_SCORE`) es de **666.75** puntos, con una desviaci√≥n est√°ndar de **45.02**, y valores entre **480.0 y 820.2**.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Interpretaci√≥n\n",
    "El dataset est√° **limpio, completo y num√©rico**, lo que lo hace ideal para aplicar algoritmos de regresi√≥n.  \n",
    "Las conversiones categ√≥ricas aseguran que los modelos puedan procesar todas las variables sin errores de tipo.  \n",
    "Este paso deja listo el entorno para dividir los datos en entrenamiento y prueba (que se realiza en el siguiente bloque).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4e0d7-e20f-436b-bdbc-02611e8e9fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93da7c5c-812e-420f-9470-840a5135625a",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo `X, y`\n",
    "\n",
    "Este bloque ejecuta la instrucci√≥n `X, y` para **visualizar el contenido de las dos estructuras de datos principales** creadas en el paso anterior:\n",
    "\n",
    "- **`X`** contiene todas las **variables predictoras**, es decir, las columnas que se usar√°n para entrenar el modelo y explicar el comportamiento del bienestar laboral.  \n",
    "- **`y`** es la **variable objetivo** que el modelo intentar√° predecir: `WORK_LIFE_BALANCE_SCORE`.\n",
    "\n",
    "En el c√≥digo anterior (`Code 1`), se eliminaron las columnas `Timestamp` y la variable objetivo del conjunto `X` para evitar duplicidades, mientras que `y` qued√≥ con los valores de la columna que representa el equilibrio vida‚Äìtrabajo.\n",
    "\n",
    "Al ejecutar `X, y`, Jupyter muestra una vista combinada:  \n",
    "primero una parte del DataFrame `X` (variables independientes), y despu√©s la Serie `y` (variable dependiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156d222a-9435-457c-aba8-915815a5f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       FRUITS_VEGGIES  DAILY_STRESS  PLACES_VISITED  CORE_CIRCLE  \\\n",
       " 0                   3             3               2            5   \n",
       " 1                   2             4               4            3   \n",
       " 2                   2             4               3            4   \n",
       " 3                   3             4              10            3   \n",
       " 4                   5             1               3            3   \n",
       " ...               ...           ...             ...          ...   \n",
       " 15967               3             4               0            4   \n",
       " 15968               3             4               6            8   \n",
       " 15969               4             4               0           10   \n",
       " 15970               1             1              10            8   \n",
       " 15971               5             5               0            2   \n",
       " \n",
       "        SUPPORTING_OTHERS  SOCIAL_NETWORK  ACHIEVEMENT  DONATION  BMI_RANGE  \\\n",
       " 0                      0               5            2         0          1   \n",
       " 1                      8              10            5         2          2   \n",
       " 2                      4              10            3         2          2   \n",
       " 3                     10               7            2         5          2   \n",
       " 4                     10               4            2         4          2   \n",
       " ...                  ...             ...          ...       ...        ...   \n",
       " 15967                  0              10            0         4          2   \n",
       " 15968                  7               4            6         3          1   \n",
       " 15969                 10               8            6         5          1   \n",
       " 15970                  2               7            3         2          1   \n",
       " 15971                 10              10            5         1          2   \n",
       " \n",
       "        TODO_COMPLETED  ...  LIVE_VISION  SLEEP_HOURS  LOST_VACATION  \\\n",
       " 0                   6  ...            0            7              5   \n",
       " 1                   5  ...            5            8              2   \n",
       " 2                   2  ...            5            8             10   \n",
       " 3                   3  ...            0            5              7   \n",
       " 4                   5  ...            0            7              0   \n",
       " ...               ...  ...          ...          ...            ...   \n",
       " 15967               8  ...            7            7              0   \n",
       " 15968               7  ...            5            6              0   \n",
       " 15969               7  ...            2            7              0   \n",
       " 15970               6  ...            5            8              7   \n",
       " 15971               7  ...            5            8              5   \n",
       " \n",
       "        DAILY_SHOUTING  SUFFICIENT_INCOME  PERSONAL_AWARDS  TIME_FOR_PASSION  \\\n",
       " 0                   5                  1                4                 0   \n",
       " 1                   2                  2                3                 2   \n",
       " 2                   2                  2                4                 8   \n",
       " 3                   5                  1                5                 2   \n",
       " 4                   0                  2                8                 1   \n",
       " ...               ...                ...              ...               ...   \n",
       " 15967               1                  1                5                 2   \n",
       " 15968               0                  2               10                 5   \n",
       " 15969               1                  2               10                 1   \n",
       " 15970               2                  2                1                 6   \n",
       " 15971               2                  2                1                 8   \n",
       " \n",
       "        WEEKLY_MEDITATION  AGE  GENDER  \n",
       " 0                      5    1       0  \n",
       " 1                      6    1       0  \n",
       " 2                      3    1       0  \n",
       " 3                      0    2       0  \n",
       " 4                      5    2       0  \n",
       " ...                  ...  ...     ...  \n",
       " 15967                  5    2       0  \n",
       " 15968                  8    0       0  \n",
       " 15969                 10    0       1  \n",
       " 15970                  8    0       0  \n",
       " 15971                  4    0       0  \n",
       " \n",
       " [15972 rows x 22 columns],\n",
       " 0        609.5\n",
       " 1        655.6\n",
       " 2        631.6\n",
       " 3        622.7\n",
       " 4        663.9\n",
       "          ...  \n",
       " 15967    644.5\n",
       " 15968    714.9\n",
       " 15969    716.6\n",
       " 15970    682.0\n",
       " 15971    651.4\n",
       " Name: WORK_LIFE_BALANCE_SCORE, Length: 15972, dtype: float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X , y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea3a96-6140-44f1-bd38-9b963112ab1f",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n del resultado\n",
    "\n",
    "El resultado confirma que la separaci√≥n de variables se realiz√≥ correctamente:\n",
    "\n",
    "- **`X` (predictoras):**  \n",
    "  Contiene **22 columnas num√©ricas**, todas relacionadas con h√°bitos, emociones o condiciones de bienestar.  \n",
    "  Ejemplos:  \n",
    "  - `FRUITS_VEGGIES`: consumo de frutas y verduras.  \n",
    "  - `DAILY_STRESS`: nivel de estr√©s diario (ya codificado num√©ricamente).  \n",
    "  - `BMI_RANGE`: rango de √≠ndice de masa corporal.  \n",
    "  - `SLEEP_HOURS`, `DAILY_STEPS`, `SOCIAL_NETWORK`, `TIME_FOR_PASSION`, etc.  \n",
    "  - `AGE` y `GENDER` tambi√©n est√°n representadas en formato num√©rico.  \n",
    "  Cada fila representa a un individuo.\n",
    "\n",
    "- **`y` (objetivo):**  \n",
    "  Es una **serie num√©rica continua** con el puntaje de `WORK_LIFE_BALANCE_SCORE`.  \n",
    "  Los valores van aproximadamente de **480.0 a 820.2**, con una media cercana a **666.75**.  \n",
    "  Esto representa el nivel de equilibrio vida‚Äìtrabajo de cada persona.\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "El DataFrame `X` y la Serie `y` est√°n perfectamente alineados (ambos con 15,972 registros).  \n",
    "Esto asegura que el modelo pueda entrenarse sin inconsistencias y confirma que el preprocesamiento del `Code 1` fue exitoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12015b-4bdb-4e2a-8e48-41212a2af0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602c24c4-e241-4c8c-b688-5e8ba94804ed",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 2 ‚Äì Split temprano 80/20)\n",
    "\n",
    "En este bloque se realiza la **divisi√≥n del conjunto de datos** en dos subconjuntos:\n",
    "uno para **entrenar** el modelo y otro para **evaluarlo**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Descripci√≥n paso a paso\n",
    "\n",
    "- Se importa la funci√≥n `train_test_split` de `sklearn.model_selection`, que permite dividir los datos de forma aleatoria y controlada.  \n",
    "- `X` y `y` se separan en:\n",
    "  - `X_train`, `y_train`: datos usados para **entrenar** el modelo (80% del total).  \n",
    "  - `X_test`, `y_test`: datos usados para **evaluar** el modelo (20% restante).  \n",
    "- El par√°metro `random_state=RANDOM_STATE` garantiza que la divisi√≥n sea **reproducible** (si vuelves a correr el c√≥digo, obtendr√°s los mismos conjuntos).\n",
    "- `test_size=0.20` indica que el 20% de las observaciones se reserva para prueba.\n",
    "\n",
    "Finalmente, el `print()` muestra la forma (shape) de ambos subconjuntos para confirmar la divisi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a612b1-8c83-4b7e-aa82-f8b98dbd3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (12777, 22) | Test: (3195, 22)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2) Split temprano (80/20)\n",
    "# =========================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20,  random_state=RANDOM_STATE\n",
    ")\n",
    "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf743d-09fc-49ac-87d7-ba0609850cd6",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n del resultado\n",
    "\n",
    "Esto significa:\n",
    "\n",
    "- El conjunto total (15,972 registros) fue dividido correctamente en:\n",
    "  - **Entrenamiento:** 12,777 filas (80%)\n",
    "  - **Prueba:** 3,195 filas (20%)\n",
    "- Ambos conjuntos conservan las **22 columnas predictoras**, correspondientes a las variables de bienestar, h√°bitos, edad y g√©nero.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Importancia de esta divisi√≥n\n",
    "\n",
    "- El conjunto **de entrenamiento (Train)** se usar√° para **ajustar** los modelos y aprender patrones.  \n",
    "- El conjunto **de prueba (Test)** servir√° para **medir el desempe√±o real** del modelo con datos que no ha visto antes, evitando el sobreajuste (*overfitting*).\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "La separaci√≥n 80/20 asegura una base s√≥lida para validar los modelos de predicci√≥n en pasos posteriores.  \n",
    "A partir de este punto, los an√°lisis de modelado (Codes 3‚Äì10) usar√°n `X_train`, `y_train` para entrenar y `X_test`, `y_test` para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfb723-1044-465c-89b1-1f3b0c95a486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbce08b4-0cf4-4ddf-b386-964d7574feb7",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 3 ‚Äì Preprocesamiento en Pipeline)\n",
    "\n",
    "En este bloque se define el **proceso de preprocesamiento autom√°tico** que se aplicar√° a los datos antes del entrenamiento del modelo.  \n",
    "El objetivo es estandarizar y preparar las variables de forma coherente, manteniendo todo dentro de un **pipeline** que asegure reproducibilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Descripci√≥n paso a paso\n",
    "\n",
    "1. **Importaci√≥n de m√≥dulos clave:**\n",
    "   - `ColumnTransformer`: permite aplicar transformaciones diferentes a distintos tipos de columnas.  \n",
    "   - `StandardScaler`: estandariza las variables num√©ricas (media = 0, desviaci√≥n est√°ndar = 1).  \n",
    "   - `OneHotEncoder`: convierte variables categ√≥ricas en variables binarias (dummies).  \n",
    "   - `VarianceThreshold`: elimina columnas con varianza cero (sin informaci√≥n √∫til).  \n",
    "   - `ImbPipeline`: versi√≥n del pipeline que mantiene compatibilidad con librer√≠as de balanceo (aunque no se usa SMOTE en regresi√≥n).\n",
    "\n",
    "2. **Identificaci√≥n de tipos de variables:**\n",
    "   ```python\n",
    "   cat_features = X_train.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "   num_features = X_train.select_dtypes(include=[\"number\",\"bool\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7c6dca-37f3-469d-8842-e333cbda85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features num√©ricas: ['FRUITS_VEGGIES', 'DAILY_STRESS', 'PLACES_VISITED', 'CORE_CIRCLE', 'SUPPORTING_OTHERS', 'SOCIAL_NETWORK', 'ACHIEVEMENT', 'DONATION', 'BMI_RANGE', 'TODO_COMPLETED', 'FLOW', 'DAILY_STEPS', 'LIVE_VISION', 'SLEEP_HOURS', 'LOST_VACATION', 'DAILY_SHOUTING', 'SUFFICIENT_INCOME', 'PERSONAL_AWARDS', 'TIME_FOR_PASSION', 'WEEKLY_MEDITATION', 'AGE', 'GENDER']\n",
      "Features categ√≥ricas: []\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3) Preprocesamiento (en pipeline)\n",
    "# =========================================\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # imblearn solo por consistencia de API\n",
    "\n",
    "cat_features = X_train.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "num_features = X_train.select_dtypes(include=[\"number\",\"bool\"]).columns.tolist()\n",
    "\n",
    "# OneHotEncoder compatible (con fallback)\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_features),\n",
    "        (\"cat\", ohe,              cat_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "def build_pipe(model):\n",
    "    # Nota: en regresi√≥n NO se usa SMOTE\n",
    "    return ImbPipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"var0\", VarianceThreshold(0.0)),  # limpia columnas constantes tras OHE\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "    \n",
    "print(f\"Features num√©ricas: {num_features}\")\n",
    "print(f\"Features categ√≥ricas: {cat_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d4f76-4893-4408-8cd7-92ca7d0a37c7",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n del resultado\n",
    "\n",
    "\n",
    "Esto significa que **todas las variables fueron detectadas como num√©ricas**, ya que las categ√≥ricas (`AGE`, `GENDER`, `DAILY_STRESS`) se transformaron en el Code 1.  \n",
    "Por lo tanto, el pipeline aplicar√° **solo el escalado num√©rico** y no realizar√° codificaci√≥n categ√≥rica.  \n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "El preprocesamiento est√° correctamente configurado y listo para usarse con los modelos de regresi√≥n.  \n",
    "A partir de este punto, cualquier modelo que pase por `build_pipe()` recibir√° datos normalizados y sin columnas redundantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a7cfe-e61b-4e0c-9d08-184d3198016f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cee611f-333a-43d5-97c9-bb1a15c42296",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 4)\n",
    "\n",
    "En este bloque se definen los **modelos candidatos de regresi√≥n** que se evaluar√°n m√°s adelante.  \n",
    "Cada modelo se guarda dentro de una lista llamada `candidates`, junto con un nombre corto que servir√° como identificador.  \n",
    "Estos modelos representan distintos enfoques de aprendizaje autom√°tico:\n",
    "\n",
    "- **Modelos lineales:** `LinearRegression`, `Ridge`, `Lasso`, `ElasticNet`.  \n",
    "- **Modelos basados en vecinos:** `KNeighborsRegressor`.  \n",
    "- **Modelos de √°rbol:** `DecisionTreeRegressor`, `RandomForestRegressor`.  \n",
    "- **Red neuronal:** `MLPRegressor` (Multilayer Perceptron).  \n",
    "- **Modelos de boosting:** `XGBRegressor`, `LGBMRegressor`, `CatBoostRegressor`.\n",
    "\n",
    "Cada modelo tiene configuraciones b√°sicas y una semilla (`random_state=RANDOM_STATE`) para asegurar resultados reproducibles.  \n",
    "Esta colecci√≥n de candidatos se usar√° en la siguiente etapa (Code 5) para comparar su rendimiento mediante validaci√≥n cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fbc8485-a82e-4c51-8a61-c2a4955fb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 4) Modelos candidatos (REGRESI√ìN)\n",
    "# =========================================\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "candidates = [\n",
    "    (\"LR\",  LinearRegression()),\n",
    "    (\"RG\",  Ridge(random_state=RANDOM_STATE)),\n",
    "    (\"LS\",  Lasso(random_state=RANDOM_STATE, max_iter=5000)),\n",
    "    (\"EN\",  ElasticNet(random_state=RANDOM_STATE, max_iter=5000)),\n",
    "    (\"KNR\", KNeighborsRegressor()),\n",
    "    (\"DTR\", DecisionTreeRegressor(random_state=RANDOM_STATE)),\n",
    "    (\"RFR\", RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)),\n",
    "    (\"MLP\", MLPRegressor(hidden_layer_sizes=(64,), max_iter=800, random_state=RANDOM_STATE)),\n",
    "    (\"XGB\", XGBRegressor(tree_method=\"hist\", random_state=RANDOM_STATE,\n",
    "                         n_estimators=400, learning_rate=0.05, max_depth=6,\n",
    "                         subsample=0.9, colsample_bytree=0.9, n_jobs=-1)),\n",
    "    (\"LGB\", LGBMRegressor(n_estimators=500, learning_rate=0.05, max_depth=-1,\n",
    "                          subsample=0.9, colsample_bytree=0.9,\n",
    "                          random_state=RANDOM_STATE, n_jobs=-1, verbosity=-1)),\n",
    "    (\"CAT\", CatBoostRegressor(iterations=600, learning_rate=0.05, depth=6,\n",
    "                              random_state=RANDOM_STATE, l2_leaf_reg=3.0,\n",
    "                              verbose=False, allow_writing_files=False, thread_count=-1)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609bf12f-6d9a-44cf-a903-b99c99c81408",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n del bloque\n",
    "\n",
    "Aunque este bloque no genera una salida visible, su funci√≥n es **preparar la lista de modelos** que competir√°n entre s√≠.  \n",
    "Cada modelo tiene una naturaleza distinta:\n",
    "- Algunos aprenden relaciones lineales entre variables.  \n",
    "- Otros, como los de √°rboles o redes neuronales, capturan **patrones no lineales**.  \n",
    "- Los m√©todos de *boosting* (XGB, LGB, CAT) combinan muchos √°rboles para lograr gran precisi√≥n.\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "El resultado de este paso es una colecci√≥n de modelos almacenada en `candidates`.  \n",
    "En los pr√≥ximos pasos, esta lista ser√° usada para entrenar, evaluar y seleccionar el mejor modelo predictivo de bienestar laboral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439491c-cf31-4012-86e2-379817578e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4bb58e3-4e27-456c-9abf-31eae3c46bb4",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 5 Baseline con CV)\n",
    "\n",
    "En este bloque se realiza una **evaluaci√≥n inicial (‚Äúbaseline‚Äù)** de todos los modelos candidatos definidos anteriormente, utilizando **validaci√≥n cruzada (Cross-Validation, CV)**.\n",
    "\n",
    "### üîπ Descripci√≥n del proceso\n",
    "1. Se define un esquema de validaci√≥n cruzada `KFold` con **5 divisiones (n_splits=5)** y barajado aleatorio de los datos.  \n",
    "2. Se establecen las m√©tricas de evaluaci√≥n:\n",
    "   - `RMSE` ‚Üí Error cuadr√°tico medio ra√≠z (cuanto m√°s bajo, mejor).  \n",
    "   - `MAE` ‚Üí Error absoluto medio.  \n",
    "   - `R¬≤` ‚Üí Coeficiente de determinaci√≥n (cuanto m√°s cercano a 1, mejor).  \n",
    "3. Para cada modelo en `candidates`:\n",
    "   - Se construye su pipeline (`build_pipe(model)`), que incluye preprocesamiento y modelo.  \n",
    "   - Se ejecuta `cross_validate()` para calcular las m√©tricas promedio en las 5 particiones de los datos.  \n",
    "   - Se imprimen los resultados de cada modelo.  \n",
    "4. Finalmente, los resultados se guardan en un DataFrame (`baseline_df`) y se ordenan seg√∫n el menor RMSE.  \n",
    "   El modelo con mejor desempe√±o se guarda como **`baseline_best_model`**.\n",
    "\n",
    "Este paso sirve como punto de partida para comparar el rendimiento de los modelos antes de aplicar ajustes o tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b245143-7bd0-4971-999f-4955066c979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LR | RMSE 0.751 | MAE 0.666 | R¬≤ 1.000\n",
      " RG | RMSE 0.751 | MAE 0.666 | R¬≤ 1.000\n",
      " LS | RMSE 2.662 | MAE 2.127 | R¬≤ 0.997\n",
      " EN | RMSE 7.008 | MAE 5.638 | R¬≤ 0.976\n",
      "KNR | RMSE 9.286 | MAE 7.271 | R¬≤ 0.958\n",
      "DTR | RMSE 23.352 | MAE 17.884 | R¬≤ 0.732\n",
      "RFR | RMSE 11.242 | MAE 8.791 | R¬≤ 0.938\n",
      "MLP | RMSE 0.514 | MAE 0.349 | R¬≤ 1.000\n",
      "XGB | RMSE 4.533 | MAE 3.526 | R¬≤ 0.990\n",
      "LGB | RMSE 3.923 | MAE 3.057 | R¬≤ 0.992\n",
      "CAT | RMSE 1.090 | MAE 0.834 | R¬≤ 0.999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.514065</td>\n",
       "      <td>0.348990</td>\n",
       "      <td>0.999868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.750922</td>\n",
       "      <td>0.665878</td>\n",
       "      <td>0.999723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RG</td>\n",
       "      <td>0.750923</td>\n",
       "      <td>0.665986</td>\n",
       "      <td>0.999723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAT</td>\n",
       "      <td>1.089683</td>\n",
       "      <td>0.834314</td>\n",
       "      <td>0.999416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LS</td>\n",
       "      <td>2.661936</td>\n",
       "      <td>2.127422</td>\n",
       "      <td>0.996518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGB</td>\n",
       "      <td>3.922845</td>\n",
       "      <td>3.057387</td>\n",
       "      <td>0.992437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGB</td>\n",
       "      <td>4.533472</td>\n",
       "      <td>3.525814</td>\n",
       "      <td>0.989900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN</td>\n",
       "      <td>7.008498</td>\n",
       "      <td>5.638100</td>\n",
       "      <td>0.975868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNR</td>\n",
       "      <td>9.286199</td>\n",
       "      <td>7.271074</td>\n",
       "      <td>0.957625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RFR</td>\n",
       "      <td>11.241599</td>\n",
       "      <td>8.790519</td>\n",
       "      <td>0.937895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTR</td>\n",
       "      <td>23.351934</td>\n",
       "      <td>17.883552</td>\n",
       "      <td>0.731925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model       rmse        mae        r2\n",
       "7    MLP   0.514065   0.348990  0.999868\n",
       "0     LR   0.750922   0.665878  0.999723\n",
       "1     RG   0.750923   0.665986  0.999723\n",
       "10   CAT   1.089683   0.834314  0.999416\n",
       "2     LS   2.661936   2.127422  0.996518\n",
       "9    LGB   3.922845   3.057387  0.992437\n",
       "8    XGB   4.533472   3.525814  0.989900\n",
       "3     EN   7.008498   5.638100  0.975868\n",
       "4    KNR   9.286199   7.271074  0.957625\n",
       "6    RFR  11.241599   8.790519  0.937895\n",
       "5    DTR  23.351934  17.883552  0.731925"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Baseline ganador: MLP\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 5) Baseline con CV (sin tuning)\n",
    "# =========================================\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring = {\n",
    "    \"rmse\": \"neg_root_mean_squared_error\",\n",
    "    \"mae\":  \"neg_mean_absolute_error\",\n",
    "    \"r2\":   \"r2\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in candidates:\n",
    "    pipe = build_pipe(model)\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    row = {\n",
    "        \"model\": name,\n",
    "        \"rmse\": -scores[\"test_rmse\"].mean(),\n",
    "        \"mae\":  -scores[\"test_mae\"].mean(),\n",
    "        \"r2\":    scores[\"test_r2\"].mean(),\n",
    "    }\n",
    "    rows.append(row)\n",
    "    print(f\"{name:>3} | RMSE {row['rmse']:.3f} | MAE {row['mae']:.3f} | R¬≤ {row['r2']:.3f}\")\n",
    "\n",
    "baseline_df = pd.DataFrame(rows).sort_values(\"rmse\")\n",
    "display(baseline_df)\n",
    "baseline_best_name  = baseline_df.iloc[0][\"model\"]\n",
    "baseline_best_model = dict(candidates)[baseline_best_name]\n",
    "print(f\">>> Baseline ganador: {baseline_best_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c687ccb-71e7-46dd-b707-d014192cf4a4",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n del resultado\n",
    "\n",
    "Los resultados muestran el rendimiento promedio de cada modelo durante la validaci√≥n cruzada:\n",
    "\n",
    "| Modelo | RMSE | MAE | R¬≤ |\n",
    "|:--|--:|--:|--:|\n",
    "| **MLP** (red neuronal) | 0.514 | 0.349 | 1.000 |\n",
    "| **LR / RG** (lineales) | 0.751 | 0.666 | 1.000 |\n",
    "| **CAT** (CatBoost) | 1.090 | 0.834 | 0.999 |\n",
    "| Otros (LGB, XGB, EN, KNR, RFR, DTR) | RMSE mayor | ‚Äî | ‚Äî |\n",
    "\n",
    "El mejor resultado lo obtuvo el modelo **MLPRegressor**, con un error muy bajo y un **R¬≤ ‚âà 1.00**, lo que indica un ajuste casi perfecto sobre los datos (posiblemente por las relaciones altamente determin√≠sticas del dataset sint√©tico).\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "El modelo **MLP** se selecciona como el **‚Äúbaseline ganador‚Äù**, ya que logra el menor RMSE y MAE, mostrando la mayor capacidad predictiva entre todos los modelos evaluados en esta fase inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3c1a8-3f5e-4bbd-b998-a1e084cd8744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e789bcce-dc49-424f-bf33-44b63f3fc1d8",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 6 Tuning con CV y elecci√≥n del ganador)\n",
    "\n",
    "En este bloque se realiza el **tuning o ajuste fino de hiperpar√°metros** para mejorar el desempe√±o de los modelos m√°s prometedores del baseline.  \n",
    "El proceso utiliza la t√©cnica de **b√∫squeda aleatoria (RandomizedSearchCV)** con validaci√≥n cruzada (`KFold`) para encontrar las mejores combinaciones de par√°metros que minimicen el error (RMSE).\n",
    "\n",
    "### üîπ Descripci√≥n general\n",
    "1. **Definici√≥n de esquemas de validaci√≥n:**\n",
    "   - `cv_light`: 5 particiones, para modelos livianos (r√°pidos).\n",
    "   - `cv_heavy`: 3 particiones, para modelos pesados (como RandomForest, XGB, LGB y CAT).\n",
    "\n",
    "2. **Espacios de b√∫squeda (`param_spaces`):**\n",
    "   Cada modelo tiene un rango de valores posibles para sus hiperpar√°metros (por ejemplo, `alpha`, `learning_rate`, `max_depth`, etc.).  \n",
    "   Estos rangos son muestreados aleatoriamente en cada iteraci√≥n de la b√∫squeda.\n",
    "\n",
    "3. **Modelos a ajustar (`to_tune`):**\n",
    "   Incluye Ridge, ElasticNet, RandomForest, XGBoost, LightGBM y CatBoost.  \n",
    "   Los modelos usan un solo hilo (`n_jobs=1`) para evitar saturar el sistema.\n",
    "\n",
    "4. **Configuraci√≥n de la b√∫squeda:**\n",
    "   `RandomizedSearchCV` prueba distintas combinaciones de par√°metros, usando la m√©trica **RMSE** como criterio principal de selecci√≥n (`refit=\"rmse\"`).\n",
    "\n",
    "5. **Selecci√≥n del mejor modelo:**\n",
    "   Se guardan los resultados en `best_models`, se ordenan por RMSE, y se identifica el **modelo ganador optimizado** (`best_name`, `final_pipe_opt`).\n",
    "\n",
    "Este paso afina los par√°metros internos de los modelos para obtener su mejor versi√≥n posible antes de la evaluaci√≥n final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f232e5-0ca2-4e97-9cc8-9b074a6f8f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Tuning modelo: RG\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "üîπ Tuning modelo: EN\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "üîπ Tuning modelo: RFR\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "üîπ Tuning modelo: XGB\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "üîπ Tuning modelo: LGB\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "üîπ Tuning modelo: CAT\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "‚úÖ >>> GANADOR OPTIMIZADO: RG (RMSE CV=0.751)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 6) Tuning con CV y elecci√≥n del ganador (estable)\n",
    "# =========================================\n",
    "import tempfile, shutil\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from scipy.stats import randint, uniform\n",
    "try:\n",
    "    from scipy.stats import loguniform\n",
    "except Exception:\n",
    "    from sklearn.utils.fixes import loguniform\n",
    "\n",
    "# =========================\n",
    "# Configuraci√≥n general\n",
    "# =========================\n",
    "cv_light = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_heavy = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "param_spaces = {\n",
    "    \"RG\":  {\"model__alpha\": loguniform(1e-3, 1e3)},\n",
    "    \"LS\":  {\"model__alpha\": loguniform(1e-3, 1e2)},\n",
    "    \"EN\":  {\"model__alpha\": loguniform(1e-3, 1e2), \"model__l1_ratio\": uniform(0.0, 1.0)},\n",
    "    \"KNR\": {\"model__n_neighbors\": randint(2, 50), \"model__weights\": [\"uniform\",\"distance\"], \"model__p\":[1,2]},\n",
    "    \"DTR\": {\"model__max_depth\": randint(3, 16), \"model__min_samples_leaf\": randint(1, 10)},\n",
    "    \"RFR\": {\"model__n_estimators\": randint(200, 400), \"model__max_depth\": randint(4, 12),\n",
    "            \"model__min_samples_split\": randint(2, 15), \"model__min_samples_leaf\": randint(1, 8),\n",
    "            \"model__max_features\": [\"sqrt\",\"log2\", None], \"model__bootstrap\": [True, False]},\n",
    "    \"MLP\": {\"model__alpha\": loguniform(1e-4, 1e-1), \"model__learning_rate_init\": loguniform(1e-4, 1e-2)},\n",
    "    \"XGB\": {\"model__n_estimators\": randint(200, 400), \"model__learning_rate\": loguniform(5e-3, 2e-1),\n",
    "            \"model__max_depth\": randint(3, 7), \"model__subsample\": uniform(0.7, 0.3),\n",
    "            \"model__colsample_bytree\": uniform(0.7, 0.3), \"model__min_child_weight\": randint(1, 6)},\n",
    "    \"LGB\": {\"model__n_estimators\": randint(200, 500), \"model__learning_rate\": loguniform(5e-3, 2e-1),\n",
    "            \"model__num_leaves\": randint(16, 64), \"model__max_depth\": randint(-1, 10),\n",
    "            \"model__min_child_samples\": randint(10, 40), \"model__subsample\": uniform(0.7, 0.3),\n",
    "            \"model__colsample_bytree\": uniform(0.7, 0.3), \"model__reg_lambda\": loguniform(1e-3, 10)},\n",
    "    \"CAT\": {\"model__iterations\": randint(200, 500), \"model__learning_rate\": loguniform(5e-3, 2e-1),\n",
    "            \"model__depth\": randint(4, 8), \"model__l2_leaf_reg\": loguniform(1e-2, 10),\n",
    "            \"model__border_count\": randint(32, 128)},\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Modelos a afinar\n",
    "# =========================\n",
    "to_tune = [\n",
    "    (\"RG\",  Ridge(random_state=RANDOM_STATE)),\n",
    "    (\"EN\",  ElasticNet(random_state=RANDOM_STATE, max_iter=5000)),\n",
    "    (\"RFR\", RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=1)),   # <--- 1 hilo\n",
    "    (\"XGB\", XGBRegressor(tree_method=\"hist\", random_state=RANDOM_STATE, n_jobs=1)),  # <--- 1 hilo\n",
    "    (\"LGB\", LGBMRegressor(random_state=RANDOM_STATE, n_jobs=1, verbosity=-1)),       # <--- 1 hilo\n",
    "    (\"CAT\", CatBoostRegressor(random_state=RANDOM_STATE, verbose=False,\n",
    "                              allow_writing_files=False, thread_count=1)),           # <--- 1 hilo\n",
    "]\n",
    "\n",
    "refit_metric = \"rmse\"  # minimizamos RMSE\n",
    "scoring = {\"rmse\": \"neg_root_mean_squared_error\", \"mae\": \"neg_mean_absolute_error\", \"r2\": \"r2\"}\n",
    "\n",
    "# =========================\n",
    "# Ejecuci√≥n segura del tuning\n",
    "# =========================\n",
    "best_models = []\n",
    "cache_dir = tempfile.mkdtemp(prefix=\"skcache_\")\n",
    "try:\n",
    "    for name, base_model in to_tune:\n",
    "        pipe = build_pipe(base_model)\n",
    "        try:\n",
    "            pipe.set_params(memory=cache_dir)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        heavy = name in [\"RFR\",\"XGB\",\"LGB\",\"CAT\"]\n",
    "\n",
    "        # Reducir n√∫mero de iteraciones para estabilidad\n",
    "        search = RandomizedSearchCV(\n",
    "            pipe, param_spaces[name],\n",
    "            n_iter=(8 if heavy else 6),\n",
    "            cv=(cv_heavy if heavy else cv_light),\n",
    "            scoring=scoring, refit=\"rmse\",\n",
    "            n_jobs=1,                       # <--- evita exceso de procesos\n",
    "            random_state=RANDOM_STATE,\n",
    "            verbose=1,\n",
    "            error_score=np.nan,\n",
    "            return_train_score=False\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüîπ Tuning modelo: {name}\")\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        best_models.append((name, search.best_estimator_, -search.best_score_, search.best_params_))  # RMSE positivo\n",
    "\n",
    "    best_models.sort(key=lambda x: x[2])  # menor RMSE primero\n",
    "    best_name, final_pipe_opt, best_cv_rmse, best_params = best_models[0]\n",
    "    print(f\"\\n‚úÖ >>> GANADOR OPTIMIZADO: {best_name} (RMSE CV={best_cv_rmse:.3f})\")\n",
    "finally:\n",
    "    shutil.rmtree(cache_dir, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a48c81-898b-4933-ad6b-2cfda32e4b39",
   "metadata": {},
   "source": [
    "### üîπ Interpretaci√≥n:\n",
    "- Cada l√≠nea indica el modelo que est√° siendo ajustado y cu√°ntas combinaciones de par√°metros se probaron.  \n",
    "- Al final, el modelo **Ridge Regression (RG)** obtiene el mejor desempe√±o promedio, con un **RMSE de 0.751** en validaci√≥n cruzada.  \n",
    "- Esto sugiere que Ridge ofrece **un equilibrio ideal entre precisi√≥n y estabilidad**, evitando el sobreajuste que a veces afecta a modelos m√°s complejos.\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "El modelo **Ridge (RG)** se convierte en el **ganador optimizado** de esta etapa.  \n",
    "En el siguiente paso (Code 7), se comparar√° con el modelo base (MLP) para determinar cu√°l ser√° el modelo definitivo para la evaluaci√≥n final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab628f-b452-416d-9ba6-7e37b6b6a003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60bb808a-66e8-4dbf-8b8b-b755b3107bcd",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 7)\n",
    "\n",
    "En este bloque se realiza una **comparaci√≥n justa** entre el **modelo base (baseline)** y el **modelo optimizado (tuned)** para decidir cu√°l se usar√° en la evaluaci√≥n final.\n",
    "\n",
    "### üîπ Proceso del c√≥digo:\n",
    "1. Se define una nueva validaci√≥n cruzada `same_cv` (5 particiones) con una semilla fija para asegurar que ambos modelos sean evaluados con **exactamente los mismos datos**.\n",
    "2. Se crean dos pipelines:\n",
    "   - `pipe_baseline_best`: contiene el modelo ganador del baseline (MLP).\n",
    "   - `pipe_tuned_best`: contiene el modelo ganador del tuning (Ridge).\n",
    "3. Se desactiva la cach√© (`memory=None`) para evitar conflictos al ejecutar m√∫ltiples pipelines.\n",
    "4. Se define la funci√≥n `cv_rmse()` que calcula el **RMSE promedio** de cada modelo mediante validaci√≥n cruzada.\n",
    "5. Se comparan los resultados de ambos modelos:\n",
    "   - Si la mejora del modelo ajustado supera el **1%**, se elige ese modelo.\n",
    "   - Si la mejora es menor al 1%, se mantiene el baseline (por simplicidad y estabilidad).\n",
    "\n",
    "Finalmente, se imprime el modelo seleccionado (`winner_name`) para el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01b5e18a-312c-493f-b3c1-31a0d8ea58ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline(MLP): RMSE 0.6166\n",
      "Tuned(RG): RMSE 0.7510\n",
      ">>> Modelo seleccionado para TEST: MLP\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 7) Comparaci√≥n justa (solo CV) - baseline vs ganador\n",
    "# =========================================\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"joblib\")\n",
    "\n",
    "same_cv = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Desactivar la cach√© del pipeline (evita los avisos de joblib)\n",
    "pipe_baseline_best = build_pipe(baseline_best_model)\n",
    "pipe_tuned_best    = final_pipe_opt\n",
    "\n",
    "try:\n",
    "    pipe_baseline_best.set_params(memory=None)\n",
    "    pipe_tuned_best.set_params(memory=None)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def cv_rmse(pipe, name):\n",
    "    s = cross_validate(\n",
    "        pipe, X_train, y_train,\n",
    "        cv=same_cv,\n",
    "        scoring={\"rmse\": \"neg_root_mean_squared_error\"},\n",
    "        n_jobs=1  # evitar exceso de hilos\n",
    "    )\n",
    "    rmse = -s[\"test_rmse\"].mean()\n",
    "    print(f\"{name}: RMSE {rmse:.4f}\")\n",
    "    return rmse\n",
    "\n",
    "rmse_base = cv_rmse(pipe_baseline_best, f\"Baseline({baseline_best_name})\")\n",
    "rmse_tune = cv_rmse(pipe_tuned_best,   f\"Tuned({best_name})\")\n",
    "\n",
    "# Regla: si la mejora < 1% del RMSE base, nos quedamos con el baseline (m√°s simple)\n",
    "if (rmse_base - rmse_tune) / rmse_base >= 0.01:\n",
    "    winner_name, winner_pipe = best_name, pipe_tuned_best\n",
    "else:\n",
    "    winner_name, winner_pipe = baseline_best_name, pipe_baseline_best\n",
    "\n",
    "print(f\">>> Modelo seleccionado para TEST: {winner_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c53cf-6885-4793-ae9e-7f62c9706a49",
   "metadata": {},
   "source": [
    "### üîπ Interpretaci√≥n:\n",
    "- El modelo **MLP (Multilayer Perceptron)** logr√≥ un **RMSE = 0.6166**, mientras que el modelo **Ridge Regression (RG)** obtuvo un **RMSE = 0.7510**.  \n",
    "- Como el modelo ajustado (RG) **no mejora** al baseline, la regla del 1% indica que debe mantenerse el modelo m√°s simple y eficaz: **MLP**.\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "El modelo **MLP** se selecciona como el **modelo final** para la evaluaci√≥n en el conjunto de prueba (`TEST`).  \n",
    "Esto demuestra que la red neuronal mantiene el mejor equilibrio entre precisi√≥n y estabilidad dentro del flujo completo de validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6571118-1459-4c5f-821f-4a0dda8dccb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "689228d8-bbf8-4ca1-8234-12f9dec91a07",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 8)\n",
    "\n",
    "Este bloque define una **pol√≠tica de decisi√≥n** que se aplica a las **predicciones finales del modelo** antes de evaluarlas o mostrarlas.  \n",
    "Su prop√≥sito es **garantizar que las predicciones sean coherentes** con los valores reales observados durante el entrenamiento.\n",
    "\n",
    "### üîπ Qu√© hace el c√≥digo:\n",
    "1. **Crea un diccionario `POLICY`** con tres reglas:\n",
    "   - `clip_to_train_range`: limita las predicciones al rango observado en el conjunto de entrenamiento.  \n",
    "   - `round_to_int`: opcional para redondear si el objetivo fuera un n√∫mero entero (en este caso, no aplica).  \n",
    "   - `lower` y `upper`: almacenan los valores m√≠nimos y m√°ximos de `y_train` (480.0 y 820.2).\n",
    "\n",
    "2. **Define la funci√≥n `postprocess_preds()`**:\n",
    "   - Recibe un conjunto de predicciones (`yhat`).  \n",
    "   - Aplica las reglas de la pol√≠tica (`clip` y/o `round`).  \n",
    "   - Devuelve las predicciones ajustadas, evitando valores extremos o fuera de rango.\n",
    "\n",
    "Esta pol√≠tica es importante para mantener la **coherencia y estabilidad del modelo** en producci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9156f243-260e-43cc-b487-d5a1eb1f0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pol√≠tica aplicada: {'clip_to_train_range': True, 'round_to_int': False, 'lower': 480.0, 'upper': 820.2}\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 8) Pol√≠tica de decisi√≥n (adaptada para regresi√≥n continua)\n",
    "# =========================================\n",
    "import numpy as np\n",
    "\n",
    "# Pol√≠tica de postprocesamiento de predicciones\n",
    "# (aplicada al modelo final MLP, que predice puntajes continuos)\n",
    "POLICY = {\n",
    "    \"clip_to_train_range\": True,   # evita valores fuera del rango de entrenamiento\n",
    "    \"round_to_int\": False,         # False porque WORK_LIFE_BALANCE_SCORE es continuo\n",
    "    \"lower\": float(y_train.min()), # valor m√≠nimo observado en el TRAIN\n",
    "    \"upper\": float(y_train.max()), # valor m√°ximo observado en el TRAIN\n",
    "}\n",
    "\n",
    "print(\"Pol√≠tica aplicada:\", POLICY)\n",
    "\n",
    "def postprocess_preds(yhat, policy=POLICY):\n",
    "    \"\"\"\n",
    "    Aplica la pol√≠tica de decisi√≥n a las predicciones:\n",
    "    1. Recorta valores fuera del rango del entrenamiento.\n",
    "    2. Redondea si se indica (no usado aqu√≠ porque el objetivo no es entero).\n",
    "    \"\"\"\n",
    "    ypp = np.array(yhat, copy=True)\n",
    "    if policy.get(\"clip_to_train_range\", False):\n",
    "        ypp = np.clip(ypp, policy[\"lower\"], policy[\"upper\"])\n",
    "    if policy.get(\"round_to_int\", False):\n",
    "        ypp = np.rint(ypp).astype(int)\n",
    "    return ypp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4da8dd-eef3-41d0-a9e8-9099e74bc02b",
   "metadata": {},
   "source": [
    "### üîπ Interpretaci√≥n:\n",
    "- Las predicciones del modelo **se limitar√°n entre 480.0 y 820.2**, que son los valores reales m√≠nimos y m√°ximos observados en el conjunto de entrenamiento.  \n",
    "- No se aplicar√° redondeo (`round_to_int=False`) porque la variable objetivo **WORK_LIFE_BALANCE_SCORE** es **continua**, no entera.  \n",
    "- Esta pol√≠tica evita que el modelo produzca valores imposibles, como 300 o 900, garantizando que los resultados se mantengan dentro del rango razonable del fen√≥meno estudiado.\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "La pol√≠tica est√° correctamente configurada para un modelo de regresi√≥n continua y se aplicar√° autom√°ticamente en los pr√≥ximos pasos de evaluaci√≥n (Code 9 y posteriores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ee8ed-9634-4e22-bb3f-8736f1a62ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18feb00f-fadc-432c-8873-003534108afb",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 9)\n",
    "\n",
    "En este paso se realiza la **evaluaci√≥n final del modelo ganador (MLP)** sobre el conjunto de **TEST**, que representa los datos nunca vistos durante el entrenamiento.  \n",
    "Aqu√≠ se mide el rendimiento real y se visualiza la calidad de las predicciones.\n",
    "\n",
    "### üîπ Qu√© hace el c√≥digo:\n",
    "1. **Entrena el modelo final:**  \n",
    "   `winner_pipe.fit(X_train, y_train)` entrena el pipeline con todos los datos de entrenamiento.\n",
    "\n",
    "2. **Genera predicciones:**  \n",
    "   `y_pred = winner_pipe.predict(X_test)` calcula los valores predichos para el conjunto de prueba.\n",
    "\n",
    "3. **Aplica la pol√≠tica de decisi√≥n (Code 8):**  \n",
    "   `postprocess_preds()` garantiza que las predicciones se mantengan dentro del rango observado en entrenamiento.\n",
    "\n",
    "4. **Calcula m√©tricas de desempe√±o:**  \n",
    "   - **RMSE:** ra√≠z del error cuadr√°tico medio ‚Üí mide desviaci√≥n promedio.  \n",
    "   - **MAE:** error absoluto medio ‚Üí mide cu√°nto se equivoca el modelo en promedio.  \n",
    "   - **R¬≤:** coeficiente de determinaci√≥n ‚Üí qu√© tan bien el modelo explica la variabilidad del dato real.\n",
    "\n",
    "5. **Muestra una vista r√°pida de predicciones reales vs. estimadas** para los primeros 10 casos.\n",
    "\n",
    "6. **Genera una visualizaci√≥n:**  \n",
    "   El gr√°fico muestra en el eje X los valores reales (`y_test`) y en el eje Y las predicciones (`y_pp`).  \n",
    "   - La l√≠nea roja punteada indica el comportamiento ideal (cuando predicci√≥n = valor real).  \n",
    "   - Los puntos azules representan los resultados del modelo: cuanto m√°s cerca est√©n de la l√≠nea roja, **mejor precisi√≥n tiene**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292e9f62-5cb2-4de1-85c6-6ebcf4c98acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÅ Evaluando modelo final en TEST: MLP\n",
      "\n",
      "üìä RESULTADOS EN TEST:\n",
      "RMSE: 0.4150\n",
      "MAE : 0.2818\n",
      "R¬≤  : 0.9999\n",
      "\n",
      "üîç Predicciones de ejemplo (primeros 10):\n",
      " y_true     y_pred\n",
      "  644.3 643.699352\n",
      "  563.7 563.470621\n",
      "  621.2 621.001325\n",
      "  704.3 704.169841\n",
      "  694.5 694.457690\n",
      "  712.5 712.626727\n",
      "  621.8 621.659961\n",
      "  728.7 728.860708\n",
      "  687.9 688.322718\n",
      "  690.5 690.932009\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 9) Evaluaci√≥n final en TEST (adaptado)\n",
    "# =========================================\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\nüèÅ Evaluando modelo final en TEST: {winner_name}\")\n",
    "\n",
    "# Entrenar el modelo ganador (MLP en tu caso)\n",
    "winner_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en TEST\n",
    "y_pred = winner_pipe.predict(X_test)\n",
    "\n",
    "# Aplicar pol√≠tica de postprocesamiento (definida en code 8)\n",
    "y_pp = postprocess_preds(y_pred, POLICY)\n",
    "\n",
    "# =========================\n",
    "# M√©tricas finales en TEST\n",
    "# =========================\n",
    "rmse = mean_squared_error(y_test, y_pp, squared=False)\n",
    "mae  = mean_absolute_error(y_test, y_pp)\n",
    "r2   = r2_score(y_test, y_pp)\n",
    "\n",
    "print(f\"\\nüìä RESULTADOS EN TEST:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R¬≤  : {r2:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# Vista r√°pida (primeros 10)\n",
    "# =========================\n",
    "preview = pd.DataFrame({\n",
    "    \"y_true\": y_test.reset_index(drop=True),\n",
    "    \"y_pred\": pd.Series(y_pp)\n",
    "}).head(10)\n",
    "\n",
    "print(\"\\nüîç Predicciones de ejemplo (primeros 10):\")\n",
    "print(preview.to_string(index=False))\n",
    "\n",
    "# =========================\n",
    "# Visualizaci√≥n (opcional)\n",
    "# =========================\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pp, alpha=0.4)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         \"r--\", lw=2, label=\"Ideal (y = ≈∑)\")\n",
    "plt.xlabel(\"Valor real (y_test)\")\n",
    "plt.ylabel(\"Predicci√≥n (y_pp)\")\n",
    "plt.title(f\"Predicciones en TEST ‚Äî {winner_name}\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80f3c1-1076-4381-86f7-2b3cb0911121",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n del resultado\n",
    "\n",
    "**Predicciones de ejemplo (primeros 10):**\n",
    "| y_true | y_pred |\n",
    "|--------|--------|\n",
    "| 644.3  | 643.7  |\n",
    "| 563.7  | 563.5  |\n",
    "| 621.2  | 621.0  |\n",
    "| 704.3  | 704.2  |\n",
    "| 694.5  | 694.5  |\n",
    "| 712.5  | 712.6  |\n",
    "| 621.8  | 621.7  |\n",
    "| 728.7  | 728.9  |\n",
    "| 687.9  | 688.3  |\n",
    "| 690.5  | 690.9  |\n",
    "\n",
    "**Gr√°fico de dispersi√≥n:**  \n",
    "El gr√°fico muestra una correlaci√≥n **casi perfecta** entre las predicciones y los valores reales.  \n",
    "La nube de puntos se alinea estrechamente con la l√≠nea roja (ideal), lo que confirma que el modelo **predice con gran precisi√≥n**.\n",
    "\n",
    "### üîπ Interpretaci√≥n:\n",
    "- **RMSE (0.415)** y **MAE (0.282)** son muy bajos ‚Üí los errores promedio son m√≠nimos.  \n",
    "- **R¬≤ = 0.9999** indica que el modelo explica **m√°s del 99.99% de la variabilidad** del puntaje de balance vida-trabajo.  \n",
    "- Las diferencias entre `y_true` y `y_pred` son menores a 1 punto, lo cual es excelente para un problema de regresi√≥n continua.\n",
    "\n",
    "‚úÖ **Conclusi√≥n:**  \n",
    "El modelo **MLP** ofrece un desempe√±o sobresaliente y generaliza bien sobre datos nuevos.  \n",
    "El gr√°fico confirma su capacidad de predicci√≥n casi perfecta, validando que fue la mejor elecci√≥n para el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ba63a-e084-4aa7-9bac-c327806f512b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee91b2ac-06be-4706-96be-4e3f3fa48683",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo 10 (Interpretabilidad + breve error analysis)\n",
    "\n",
    "Este bloque analiza la **interpretabilidad** y los **errores del modelo final (MLP)**, para entender **qu√© variables influyen m√°s** en las predicciones y **d√≥nde se equivoca el modelo**.\n",
    "\n",
    "### üîπ Qu√© hace el c√≥digo:\n",
    "\n",
    "1. **Chequeo de la pol√≠tica (`clip`)**  \n",
    "   Verifica cu√°ntas predicciones fueron recortadas por estar fuera del rango de entrenamiento (`clip_low` / `clip_high`).  \n",
    "   Si ambos valores son 0%, significa que el modelo nunca predijo fuera del rango esperado.\n",
    "\n",
    "2. **Importancia de caracter√≠sticas (Permutation Importance)**  \n",
    "   Como MLP no ofrece coeficientes interpretables, se usa **Permutation Importance**:\n",
    "   - Calcula cu√°nto aumenta el error (RMSE) si se desordena una variable.  \n",
    "   - Cuanto mayor sea el impacto, **m√°s importante es la variable** para el modelo.  \n",
    "   - Se muestran las **15 m√°s influyentes** ordenadas de mayor a menor.\n",
    "\n",
    "3. **An√°lisis de errores individuales**  \n",
    "   - Calcula el **error absoluto (|y_true - y_pred|)** para cada muestra.  \n",
    "   - Muestra un resumen estad√≠stico (promedio, percentiles, m√°ximo, etc.).  \n",
    "   - Lista los **10 casos con mayor error**, junto con sus variables de entrada, para inspeccionar patrones.\n",
    "\n",
    "4. **Errores por subgrupos (GENDER y AGE)**  \n",
    "   Eval√∫a si el modelo presenta **sesgos o diferencias de error** entre grupos.  \n",
    "   Se reporta el **MAE promedio y mediano** por cada categor√≠a.\n",
    "\n",
    "Con este an√°lisis se combinan **explicabilidad global** (qu√© variables mandan) y **diagn√≥stico local** (en qu√© se equivoca el modelo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99525c07-ca07-4dc0-9ef3-02a1246ecb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† An√°lisis de interpretabilidad y errores del modelo final\n",
      "[Policy] clipped_low: 0.000% | clipped_high: 0.000%\n",
      "\n",
      "üìà Top-15 caracter√≠sticas m√°s influyentes (por permutaci√≥n):\n",
      "          feature  importance      std\n",
      "        BMI_RANGE   11.403087 0.094202\n",
      "SUFFICIENT_INCOME   10.264159 0.139139\n",
      "         DONATION    8.464927 0.089240\n",
      "    LOST_VACATION    8.421348 0.088355\n",
      "   PLACES_VISITED    7.504544 0.097738\n",
      "      DAILY_STEPS    7.440877 0.026945\n",
      "SUPPORTING_OTHERS    7.387097 0.076377\n",
      "      LIVE_VISION    7.344610 0.040301\n",
      "   SOCIAL_NETWORK    7.073842 0.073666\n",
      "  PERSONAL_AWARDS    6.939780 0.054377\n",
      "WEEKLY_MEDITATION    6.920494 0.058564\n",
      "   FRUITS_VEGGIES    6.510436 0.027356\n",
      "      CORE_CIRCLE    6.443996 0.066212\n",
      "      ACHIEVEMENT    6.211866 0.053000\n",
      "     DAILY_STRESS    6.146634 0.048849\n",
      "\n",
      "üìä Resumen del |error| absoluto:\n",
      "count    3195.000000\n",
      "mean        0.281760\n",
      "std         0.304695\n",
      "min         0.000104\n",
      "10%         0.031282\n",
      "25%         0.087681\n",
      "50%         0.194444\n",
      "75%         0.368569\n",
      "90%         0.621489\n",
      "max         3.905379\n",
      "\n",
      "‚ùå Peores 10 casos (mayor |error|):\n",
      " y_true     y_pred  abs_err  FRUITS_VEGGIES  DAILY_STRESS  PLACES_VISITED  CORE_CIRCLE  SUPPORTING_OTHERS  SOCIAL_NETWORK  ACHIEVEMENT  DONATION  BMI_RANGE  TODO_COMPLETED  FLOW  DAILY_STEPS  LIVE_VISION  SLEEP_HOURS  LOST_VACATION  DAILY_SHOUTING  SUFFICIENT_INCOME  PERSONAL_AWARDS  TIME_FOR_PASSION  WEEKLY_MEDITATION  AGE  GENDER\n",
      "  721.6 725.505379 3.905379               1             3              10           10                 10              10            4         5          2              10    10           10           10           10             10              10                  1               10                10                 10    3       1\n",
      "  647.5 650.375248 2.875248               2             5              10            8                  7               7            7         1          2               5     3            7            5            8             10               3                  1                5                 2                 10    3       0\n",
      "  499.0 501.582534 2.582534               0             6               0            0                  0               0            0         0          2               0     0           10            0            2             10              10                  1                0                 0                  0    3       1\n",
      "  668.0 670.400107 2.400107               1             6               4            4                  5               9           10         5          1               3     3            3           10            4             10               1                  2               10                 2                  4    3       1\n",
      "  597.3 599.652109 2.352109               1             0               0            3                  3               3            8         0          2               3     2           10            4            9             10               4                  1                5                 1                  0    0       1\n",
      "  741.2 743.495244 2.295244               5             5              10            5                 10               5            8         5          1               9     5            8           10            8              7               5                  2               10                10                  6    3       1\n",
      "  634.7 636.869839 2.169839               5             6               2            7                  5               5            5         1          2              10     3           10            1            9             10               3                  1               10                 2                  3    2       0\n",
      "  631.0 633.115399 2.115399               2             5               2            1                  8              10            1         1          2               7     7            4           10            5             10               6                  2                3                10                  0    1       1\n",
      "  735.3 737.333747 2.033747               2             1              10           10                  8               7            8         5          1               3     2            6           10            6              7               0                  2               10                 6                 10    3       0\n",
      "  778.2 776.226951 1.973049               5             0               8           10                 10              10           10         5          2              10    10            6           10            8              4               0                  2               10                 8                 10    1       1\n",
      "\n",
      "üìå MAE por subgrupo de GENDER:\n",
      "        count      mean    median\n",
      "GENDER                           \n",
      "0        1993  0.254630  0.186504\n",
      "1        1202  0.326744  0.210494\n",
      "\n",
      "üìå MAE por subgrupo de AGE:\n",
      "     count      mean    median\n",
      "AGE                           \n",
      "0     1207  0.260579  0.185565\n",
      "1      950  0.250787  0.179300\n",
      "2      689  0.299047  0.200892\n",
      "3      349  0.405199  0.284394\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 10) Interpretabilidad + breve error analysis\n",
    "# =========================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"\\nüß† An√°lisis de interpretabilidad y errores del modelo final\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10.1 ¬øCu√°nto recorta la pol√≠tica?\n",
    "# ------------------------------------------------------------\n",
    "raw_pred = winner_pipe.predict(X_test)\n",
    "clip_low  = (raw_pred < POLICY[\"lower\"]).mean()\n",
    "clip_high = (raw_pred > POLICY[\"upper\"]).mean()\n",
    "print(f\"[Policy] clipped_low: {clip_low:.3%} | clipped_high: {clip_high:.3%}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10.2 Importancias por Permutaci√≥n (sobre columnas originales)\n",
    "# ------------------------------------------------------------\n",
    "# Nota: El MLP no ofrece coeficientes interpretables directamente,\n",
    "# pero s√≠ podemos usar permutation importance para estimar la influencia de cada variable.\n",
    "\n",
    "r = permutation_importance(\n",
    "    winner_pipe, \n",
    "    X_test, y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "\n",
    "feat_names = X_test.columns\n",
    "imp = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feat_names,\n",
    "        \"importance\": r.importances_mean,\n",
    "        \"std\": r.importances_std\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    "    .head(15)\n",
    ")\n",
    "\n",
    "print(\"\\nüìà Top-15 caracter√≠sticas m√°s influyentes (por permutaci√≥n):\")\n",
    "print(imp.to_string(index=False))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10.3 Errores individuales: resumen y peores casos\n",
    "# ------------------------------------------------------------\n",
    "y_hat = winner_pipe.predict(X_test)\n",
    "y_pp  = postprocess_preds(y_hat, POLICY)\n",
    "res = pd.DataFrame({\n",
    "    \"y_true\": y_test.reset_index(drop=True),\n",
    "    \"y_pred\": pd.Series(y_pp)\n",
    "})\n",
    "res[\"abs_err\"] = (res[\"y_true\"] - res[\"y_pred\"]).abs()\n",
    "\n",
    "print(\"\\nüìä Resumen del |error| absoluto:\")\n",
    "print(res[\"abs_err\"].describe(percentiles=[.1, .25, .5, .75, .9]).to_string())\n",
    "\n",
    "print(\"\\n‚ùå Peores 10 casos (mayor |error|):\")\n",
    "top_bad_idx = res[\"abs_err\"].nlargest(10).index\n",
    "bad_cases = pd.concat(\n",
    "    [res.loc[top_bad_idx], X_test.reset_index(drop=True).loc[top_bad_idx]],\n",
    "    axis=1\n",
    ")\n",
    "print(bad_cases.to_string(index=False))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10.4 M√©tricas por subgrupos (ejemplo: GENDER o AGE)\n",
    "# ------------------------------------------------------------\n",
    "for col in [\"GENDER\", \"AGE\"]:\n",
    "    if col in X_test.columns:\n",
    "        by_grp = (\n",
    "            pd.concat([X_test.reset_index(drop=True)[[col]], res], axis=1)\n",
    "            .groupby(col)[\"abs_err\"]\n",
    "            .agg([\"count\", \"mean\", \"median\"])\n",
    "            .sort_index()\n",
    "        )\n",
    "        print(f\"\\nüìå MAE por subgrupo de {col}:\")\n",
    "        print(by_grp.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d13a6-52af-4a6e-ad2c-ee9f10733e71",
   "metadata": {},
   "source": [
    "üî∏ El modelo **no gener√≥ valores fuera del rango de entrenamiento**, lo cual demuestra estabilidad en sus predicciones.\n",
    "\n",
    "---\n",
    "\n",
    "**2Ô∏è‚É£ Top 15 variables m√°s influyentes:**\n",
    "| Variable | Importancia |\n",
    "|-----------|-------------|\n",
    "| BMI_RANGE | 11.40 |\n",
    "| SUFFICIENT_INCOME | 10.26 |\n",
    "| DONATION | 8.46 |\n",
    "| LOST_VACATION | 8.42 |\n",
    "| PLACES_VISITED | 7.50 |\n",
    "| DAILY_STEPS | 7.44 |\n",
    "| SUPPORTING_OTHERS | 7.39 |\n",
    "| LIVE_VISION | 7.34 |\n",
    "| SOCIAL_NETWORK | 7.07 |\n",
    "| PERSONAL_AWARDS | 6.94 |\n",
    "\n",
    "üìå **Interpretaci√≥n:**  \n",
    "El modelo MLP se apoya principalmente en **factores de salud (BMI_RANGE)**, **econom√≠a personal (SUFFICIENT_INCOME)** y **h√°bitos sociales o laborales** como **DONATION** y **LOST_VACATION**.  \n",
    "Esto sugiere que el **balance vida-trabajo** depende de bienestar f√≠sico, ingresos y equilibrio entre descanso y contribuci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "**3Ô∏è‚É£ An√°lisis de errores:**\n",
    "- **MAE promedio:** 0.2818  \n",
    "- **Desviaci√≥n est√°ndar:** 0.3047  \n",
    "- La mayor√≠a de errores son **menores a 0.5 unidades**, lo que implica una precisi√≥n alt√≠sima.  \n",
    "- Los peores 10 casos muestran desviaciones m√°ximas cercanas a **3.9 puntos**, posiblemente en individuos con valores extremos o at√≠picos.\n",
    "\n",
    "---\n",
    "\n",
    "**4Ô∏è‚É£ MAE por subgrupos:**\n",
    "| Subgrupo | MAE medio |\n",
    "|-----------|-----------|\n",
    "| GENDER=0 (Female) | 0.2546 |\n",
    "| GENDER=1 (Male)   | 0.3267 |\n",
    "| AGE=3 (mayores)   | 0.4052 |\n",
    "\n",
    "üìå **Interpretaci√≥n:**  \n",
    "El modelo mantiene un desempe√±o estable entre grupos, aunque **los hombres y las personas mayores presentan errores ligeramente mayores**, lo que puede deberse a menor representatividad en esos subgrupos.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Conclusi√≥n final:**  \n",
    "El modelo **MLP** demuestra ser **muy preciso y estable**, sin predicciones fuera de rango y con excelente explicaci√≥n mediante las variables m√°s relevantes.  \n",
    "Las peque√±as diferencias de error por grupo son normales y no indican sesgo severo, confirmando que el modelo **generaliza correctamente** los patrones del bienestar laboral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e30ad-128d-4c44-a1a8-8a3d326c8968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa061696-3725-4868-b39e-f94fbc2fae59",
   "metadata": {},
   "source": [
    "## üß© Explicaci√≥n del c√≥digo (Code 11)\n",
    "\n",
    "Este bloque complementa el an√°lisis de interpretabilidad, mostrando **qu√© variables mantienen mayor influencia dentro del pipeline completo**, es decir, **despu√©s del preprocesamiento**.\n",
    "\n",
    "### üîπ Qu√© hace el c√≥digo:\n",
    "\n",
    "1. **Transformaci√≥n de los datos (`Xtr`)**  \n",
    "   Se aplican las mismas transformaciones definidas en el pipeline (`StandardScaler`, `VarianceThreshold`, etc.) para obtener la versi√≥n final de las variables que realmente ve el modelo.\n",
    "\n",
    "2. **Extracci√≥n del modelo interno (`MLP`)**  \n",
    "   Se accede directamente al modelo dentro del pipeline (`winner_pipe.named_steps[\"model\"]`) para analizarlo de forma aislada.\n",
    "\n",
    "3. **C√°lculo de importancias por permutaci√≥n (Permutation Importance)**  \n",
    "   Eval√∫a cu√°nto aumenta el error (RMSE) al alterar cada variable transformada.  \n",
    "   Cuanto mayor sea ese impacto, **mayor es la importancia de la variable** para el modelo.\n",
    "\n",
    "4. **Obtenci√≥n de nombres de caracter√≠sticas (`get_feature_names_out`)**  \n",
    "   En este caso no hay variables categ√≥ricas, por lo que los nombres mantienen el prefijo `\"num__\"` indicando que son num√©ricas.\n",
    "\n",
    "5. **Creaci√≥n del ranking de variables**  \n",
    "   Se genera un `DataFrame` con las 20 variables m√°s relevantes tras el preprocesamiento, ordenadas por su importancia media y desviaci√≥n est√°ndar.\n",
    "\n",
    "üëâ Este an√°lisis muestra **qu√© inputs el modelo MLP considera m√°s determinantes** dentro de su versi√≥n final ya estandarizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd1a25c6-9487-4f6b-9487-2e519d11675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä An√°lisis de importancia sobre features transformadas (post pipeline)\n",
      "Shape de X transformado: (3195, 22)\n",
      "\n",
      "üîù Top-20 variables m√°s influyentes (tras preprocesamiento):\n",
      "               feature  importance      std\n",
      "        num__BMI_RANGE   11.403087 0.094202\n",
      "num__SUFFICIENT_INCOME   10.264159 0.139139\n",
      "         num__DONATION    8.464927 0.089240\n",
      "    num__LOST_VACATION    8.421348 0.088355\n",
      "   num__PLACES_VISITED    7.504544 0.097738\n",
      "      num__DAILY_STEPS    7.440877 0.026945\n",
      "num__SUPPORTING_OTHERS    7.387097 0.076377\n",
      "      num__LIVE_VISION    7.344610 0.040301\n",
      "   num__SOCIAL_NETWORK    7.073842 0.073666\n",
      "  num__PERSONAL_AWARDS    6.939780 0.054377\n",
      "num__WEEKLY_MEDITATION    6.920494 0.058564\n",
      "   num__FRUITS_VEGGIES    6.510436 0.027356\n",
      "      num__CORE_CIRCLE    6.443996 0.066212\n",
      "      num__ACHIEVEMENT    6.211866 0.053000\n",
      "     num__DAILY_STRESS    6.146634 0.048849\n",
      " num__TIME_FOR_PASSION    6.084051 0.050989\n",
      "   num__DAILY_SHOUTING    6.074614 0.050134\n",
      "   num__TODO_COMPLETED    5.979164 0.062289\n",
      "             num__FLOW    5.254964 0.048034\n",
      "      num__SLEEP_HOURS    2.901514 0.028391\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 11) Importancia de caracter√≠sticas (post-pipeline, adaptado)\n",
    "# =========================================\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nüìä An√°lisis de importancia sobre features transformadas (post pipeline)\")\n",
    "\n",
    "# 11.1 Obtener las features transformadas por el preprocesador\n",
    "Xtr = winner_pipe.named_steps[\"prep\"].transform(X_test)\n",
    "\n",
    "# Verificar dimensiones\n",
    "print(f\"Shape de X transformado: {Xtr.shape}\")\n",
    "\n",
    "# 11.2 Extraer el modelo interno (MLP en este caso)\n",
    "model = winner_pipe.named_steps[\"model\"]\n",
    "\n",
    "# 11.3 Calcular importancias por permutaci√≥n (en espacio ya escalado)\n",
    "r2_perm = permutation_importance(\n",
    "    model,\n",
    "    Xtr, y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "\n",
    "# 11.4 Obtener los nombres de las variables transformadas\n",
    "# En tu caso no hay variables categ√≥ricas, as√≠ que ser√°n las mismas columnas num√©ricas originales.\n",
    "feat_names_ohe = winner_pipe.named_steps[\"prep\"].get_feature_names_out()\n",
    "\n",
    "# 11.5 Crear dataframe ordenado de importancias\n",
    "imp_ohe = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": feat_names_ohe,\n",
    "        \"importance\": r2_perm.importances_mean,\n",
    "        \"std\": r2_perm.importances_std\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "print(\"\\nüîù Top-20 variables m√°s influyentes (tras preprocesamiento):\")\n",
    "print(imp_ohe.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e0acd-3ebc-42f0-8226-539440970470",
   "metadata": {},
   "source": [
    "## üìä Interpretaci√≥n del resultado\n",
    "\n",
    "\n",
    "**Top-20 variables m√°s influyentes (tras preprocesamiento):**\n",
    "| Feature | Importance |\n",
    "|----------|-------------|\n",
    "| num__BMI_RANGE | 11.40 |\n",
    "| num__SUFFICIENT_INCOME | 10.26 |\n",
    "| num__DONATION | 8.46 |\n",
    "| num__LOST_VACATION | 8.42 |\n",
    "| num__PLACES_VISITED | 7.50 |\n",
    "| num__DAILY_STEPS | 7.44 |\n",
    "| num__SUPPORTING_OTHERS | 7.39 |\n",
    "| num__LIVE_VISION | 7.34 |\n",
    "| num__SOCIAL_NETWORK | 7.07 |\n",
    "| num__PERSONAL_AWARDS | 6.94 |\n",
    "\n",
    "### üîπ Interpretaci√≥n:\n",
    "- Las variables m√°s influyentes coinciden con las del an√°lisis anterior, confirmando consistencia.  \n",
    "- **BMI_RANGE** (√≠ndice de masa corporal) y **SUFFICIENT_INCOME** (ingreso suficiente) son las m√°s determinantes, lo que indica que **bienestar f√≠sico y financiero** tienen gran impacto en el equilibrio vida-trabajo.  \n",
    "- Variables como **DONATION**, **LOST_VACATION**, y **PLACES_VISITED** tambi√©n destacan, mostrando que la participaci√≥n social, descanso y experiencias personales influyen fuertemente en el bienestar general.\n",
    "\n",
    "### üîπ Conclusi√≥n:\n",
    "El modelo **MLP** mantiene una estructura interpretativa estable incluso tras el preprocesamiento, lo que valida que las **variables de salud, ingresos y actividades personales** son las claves para predecir el **Work-Life Balance Score**.  \n",
    "Este resultado refuerza la coherencia del modelo y su alineaci√≥n con comportamientos humanos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f82d9-0793-4f4c-a93e-553fdf7e4a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17556694-e26a-4c8d-91fa-c7d84535776b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num__BMI_RANGE</td>\n",
       "      <td>11.403087</td>\n",
       "      <td>0.094202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num__SUFFICIENT_INCOME</td>\n",
       "      <td>10.264159</td>\n",
       "      <td>0.139139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num__DONATION</td>\n",
       "      <td>8.464927</td>\n",
       "      <td>0.089240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>num__LOST_VACATION</td>\n",
       "      <td>8.421348</td>\n",
       "      <td>0.088355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num__PLACES_VISITED</td>\n",
       "      <td>7.504544</td>\n",
       "      <td>0.097738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>num__DAILY_STEPS</td>\n",
       "      <td>7.440877</td>\n",
       "      <td>0.026945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__SUPPORTING_OTHERS</td>\n",
       "      <td>7.387097</td>\n",
       "      <td>0.076377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>num__LIVE_VISION</td>\n",
       "      <td>7.344610</td>\n",
       "      <td>0.040301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num__SOCIAL_NETWORK</td>\n",
       "      <td>7.073842</td>\n",
       "      <td>0.073666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num__PERSONAL_AWARDS</td>\n",
       "      <td>6.939780</td>\n",
       "      <td>0.054377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>num__WEEKLY_MEDITATION</td>\n",
       "      <td>6.920494</td>\n",
       "      <td>0.058564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__FRUITS_VEGGIES</td>\n",
       "      <td>6.510436</td>\n",
       "      <td>0.027356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num__CORE_CIRCLE</td>\n",
       "      <td>6.443996</td>\n",
       "      <td>0.066212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num__ACHIEVEMENT</td>\n",
       "      <td>6.211866</td>\n",
       "      <td>0.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__DAILY_STRESS</td>\n",
       "      <td>6.146634</td>\n",
       "      <td>0.048849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num__TIME_FOR_PASSION</td>\n",
       "      <td>6.084051</td>\n",
       "      <td>0.050989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num__DAILY_SHOUTING</td>\n",
       "      <td>6.074614</td>\n",
       "      <td>0.050134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num__TODO_COMPLETED</td>\n",
       "      <td>5.979164</td>\n",
       "      <td>0.062289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>num__FLOW</td>\n",
       "      <td>5.254964</td>\n",
       "      <td>0.048034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>num__SLEEP_HOURS</td>\n",
       "      <td>2.901514</td>\n",
       "      <td>0.028391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance       std\n",
       "8           num__BMI_RANGE   11.403087  0.094202\n",
       "16  num__SUFFICIENT_INCOME   10.264159  0.139139\n",
       "7            num__DONATION    8.464927  0.089240\n",
       "14      num__LOST_VACATION    8.421348  0.088355\n",
       "2      num__PLACES_VISITED    7.504544  0.097738\n",
       "11        num__DAILY_STEPS    7.440877  0.026945\n",
       "4   num__SUPPORTING_OTHERS    7.387097  0.076377\n",
       "12        num__LIVE_VISION    7.344610  0.040301\n",
       "5      num__SOCIAL_NETWORK    7.073842  0.073666\n",
       "17    num__PERSONAL_AWARDS    6.939780  0.054377\n",
       "19  num__WEEKLY_MEDITATION    6.920494  0.058564\n",
       "0      num__FRUITS_VEGGIES    6.510436  0.027356\n",
       "3         num__CORE_CIRCLE    6.443996  0.066212\n",
       "6         num__ACHIEVEMENT    6.211866  0.053000\n",
       "1        num__DAILY_STRESS    6.146634  0.048849\n",
       "18   num__TIME_FOR_PASSION    6.084051  0.050989\n",
       "15     num__DAILY_SHOUTING    6.074614  0.050134\n",
       "9      num__TODO_COMPLETED    5.979164  0.062289\n",
       "10               num__FLOW    5.254964  0.048034\n",
       "13        num__SLEEP_HOURS    2.901514  0.028391"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29004e26-84b4-44ac-84bb-1139c91876f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
